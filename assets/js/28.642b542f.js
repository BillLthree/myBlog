(window.webpackJsonp=window.webpackJsonp||[]).push([[28],{427:function(e,r,v){"use strict";v.r(r);var _=v(2),o=Object(_.a)({},(function(){var e=this,r=e._self._c;return r("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[r("h1",{attrs:{id:"zk简介"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#zk简介"}},[e._v("#")]),e._v(" zk简介")]),e._v(" "),r("p",[e._v("zookeeper主要用于分布式系统中的"),r("strong",[e._v("节点管理")]),e._v("。")]),e._v(" "),r("ul",[r("li",[e._v("ZooKeeper主要"),r("strong",[e._v("服务于分布式系统")]),e._v("，可以用ZooKeeper来做：统一配置管理、统一命名服务、分布式锁、集群管理。")]),e._v(" "),r("li",[e._v("使用分布式系统就无法避免对节点管理的问题(需要实时感知节点的状态、对节点进行统一管理等等)，而由于这些问题处理起来可能相对麻烦和提高了系统的复杂性，ZooKeeper作为一个能够"),r("strong",[e._v("通用")]),e._v("解决这些问题的中间件就应运而生了。")])]),e._v(" "),r("h1",{attrs:{id:"zab协议"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#zab协议"}},[e._v("#")]),e._v(" ZAB协议")]),e._v(" "),r("p",[e._v("zab包括两种基本的模式：")]),e._v(" "),r("ol",[r("li",[r("p",[e._v("崩溃恢复：主服务器意外宕机崩溃后，zab会通过"),r("strong",[e._v("leader选举机制")]),e._v("来进行恢复。")]),e._v(" "),r("p",[e._v("当选举产生了新的 Leader 服务器，同时集群中已经有"),r("strong",[e._v("过半")]),e._v("的机器与该 Leader 服务器完成了"),r("strong",[e._v("数据同步")]),e._v("之后，ZAB 协议就会退出恢复模式。")])]),e._v(" "),r("li",[r("p",[e._v("消息广播：当集群中已经有过半的 Follower 服务器完成了和 Leader 服务器的数据同步，那么整个服务框架就可以进入消息广播模式了。"),r("strong",[e._v("也就是leader可以接受客户端新的proposal请求，将新的proposal请求广播给所有的follower，如果有新加入的服务器，也会自觉地进入数据同步。")])])])]),e._v(" "),r("h2",{attrs:{id:"数据同步"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#数据同步"}},[e._v("#")]),e._v(" 数据同步")]),e._v(" "),r("p",[e._v("数据同步（类似2pc）：如果是写请求，那么请求会被转发给leader提交事务。leader会广播事务，只要超过半数节点写入成功，那么写请求就会被提交。")]),e._v(" "),r("ol",[r("li",[e._v("leader发送广播事务提议，向磁盘中写入事务日志，follower收到提议后也进行持久化（"),r("strong",[e._v("写入本地事务日志")]),e._v("），并返回"),r("strong",[e._v("ACK")]),e._v("。")]),e._v(" "),r("li",[e._v("只有当leader收到"),r("strong",[e._v("半数以上")]),e._v("的"),r("strong",[e._v("ack消息")]),e._v("后，ZK的Leader节点才会确认提交写请求，将其写入内存（内存生效才能被客户端访问）。")])]),e._v(" "),r("h2",{attrs:{id:"leader选举机制"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#leader选举机制"}},[e._v("#")]),e._v(" leader选举机制")]),e._v(" "),r("p",[e._v("leader选举机制：在 ZooKeeper 中没有选择传统的 Master/Slave 概念，而是引入了 Leader、Follower 和 Observer 三种角色。")]),e._v(" "),r("p",[e._v("这个过程大致是这样的：")]),e._v(" "),r("p",[e._v("4个阶段：选举阶段、发现阶段、同步阶段、广播阶段")]),e._v(" "),r("ol",[r("li",[r("p",[r("strong",[e._v("Leader election（选举阶段）")]),e._v("：节点在一开始都处于选举阶段，只要有一个节点得到超半数节点的票数，它就可以当选准 leader。")])]),e._v(" "),r("li",[r("p",[r("strong",[e._v("Discovery（发现阶段）")]),e._v(" ：在这个阶段，followers 跟准 leader 进行通信，leader "),r("strong",[e._v("同步 followers 最近接收的事务提议")]),e._v("。")]),e._v(" "),r("ul",[r("li",[r("p",[e._v("发现当前大多数节点接收的最新提议，并且准 leader 生成新的 epoch，让 followers 接受，更新它们的 acceptedEpoch。")])]),e._v(" "),r("li",[r("p",[e._v("准 leader 接受到来自过半Follower的确认消息ack之后，准leader 就会"),r("strong",[e._v("从这些过半的服务器中选取一个Follower 集合，并使用该集合作为初始化集合")]),e._v("，这个集合满足的最大epoch 与 zxid 都是所有集合中最大的")])])])]),e._v(" "),r("li",[r("p",[r("strong",[e._v("Synchronization（同步阶段）")]),e._v(" :同步阶段主要是利用 leader 前一阶段获得的最新提议历史，"),r("strong",[e._v("同步集群中所有的副本")]),e._v("。同步完成之后 准 leader 才会成为真正的 leader。")])]),e._v(" "),r("li",[r("p",[r("strong",[e._v("Broadcast（广播阶段）")]),e._v(" :到了这个阶段，ZooKeeper 集群才能"),r("strong",[e._v("正式对外提供事务服务")]),e._v("，同时如果有新的节点加入，还需要对新节点进行同步。")])])]),e._v(" "),r("p",[e._v("引入Observer的意义：既保证了 ZooKeeper 集群的伸缩性，又避免了因为"),r("strong",[e._v("过多的服务器参与投票")]),e._v("相关的操作而影响 ZooKeeper 集群对事物的处理速度。")]),e._v(" "),r("ul",[r("li",[e._v("随着集群中 Follower 服务器的数量越来越多，一次写入等相关操作的投票也就变得越来越"),r("strong",[e._v("复杂")]),e._v("，并且 Follow 服务器之间彼此的网络通信也变得越来越"),r("strong",[e._v("耗时")]),e._v("，导致随着 Follow 服务器数量的逐步增加，事务性的"),r("strong",[e._v("处理性能反而变得越来越低")]),e._v("。")])]),e._v(" "),r("h2",{attrs:{id:"zk节点角色"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#zk节点角色"}},[e._v("#")]),e._v(" zk节点角色")]),e._v(" "),r("p",[e._v("在 ZooKeeper 中没有选择传统的 Master/Slave 概念，而是引入了 Leader、Follower 和 Observer 三种角色。")]),e._v(" "),r("p",[e._v("ZooKeeper 集群中的所有机器通过一个 "),r("strong",[e._v("Leader 选举过程")]),e._v(" 来选定一台称为 “"),r("strong",[e._v("Leader")]),e._v("” 的机器，Leader 既可以为客户端提供写服务又能提供读服务。除了 Leader 外，"),r("strong",[e._v("Follower")]),e._v(" 和 "),r("strong",[e._v("Observer")]),e._v(" 都只能提供读服务。Follower 和 Observer 唯一的区别在于 Observer 机器不参与 Leader 的选举过程，也不参与写操作的“过半写成功”策略，因此 Observer 机器可以在不影响写性能的情况下提升集群的读性能。")]),e._v(" "),r("p",[r("strong",[e._v("ZooKeeper 集群中的服务器状态")])]),e._v(" "),r("ul",[r("li",[r("strong",[e._v("LOOKING")]),e._v(" ：寻找 Leader。")]),e._v(" "),r("li",[r("strong",[e._v("LEADING")]),e._v(" ：Leader 状态，对应的节点为 Leader。")]),e._v(" "),r("li",[r("strong",[e._v("FOLLOWING")]),e._v(" ：Follower 状态，对应的节点为 Follower。")]),e._v(" "),r("li",[r("strong",[e._v("OBSERVING")]),e._v(" ：Observer 状态，对应节点为 Observer，该节点不参与 Leader 选举。")])]),e._v(" "),r("h1",{attrs:{id:"脑裂问题"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#脑裂问题"}},[e._v("#")]),e._v(" 脑裂问题")]),e._v(" "),r("p",[r("strong",[e._v("何为集群脑裂？")])]),e._v(" "),r("p",[e._v("对于一个集群，通常多台机器会部署在不同机房，来提高这个集群的可用性。保证可用性的同时，会发生一种机房间网络线路故障，导致机房间网络不通，而集群被割裂成几个小集群。这时候子集群各自选主导致“脑裂”的情况。")]),e._v(" "),r("p",[e._v("举例说明：比如现在有一个由 6 台服务器所组成的一个集群，部署在了 2 个机房，每个机房 3 台。正常情况下只有 1 个 leader，但是当两个机房中间网络断开的时候，每个机房的 3 台服务器都会认为另一个机房的 3 台服务器下线，而选出自己的 leader 并对外提供服务。若没有过半机制，当网络恢复的时候会发现有 2 个 leader。仿佛是 1 个大脑（leader）分散成了 2 个大脑，这就发生了脑裂现象。脑裂期间 2 个大脑都可能对外提供了服务，这将会带来数据一致性等问题。")]),e._v(" "),r("p",[r("strong",[e._v("过半机制是如何防止脑裂现象产生的？")])]),e._v(" "),r("p",[e._v("ZooKeeper 的"),r("strong",[e._v("过半机制")]),e._v("导致不可能产生 2 个 leader，因为少于等于一半是不可能产生 leader 的，这就使得不论机房的机器如何分配都不可能发生脑裂。")]),e._v(" "),r("p",[e._v("zookeeper的过半机制：在领导者选举的过程中，如果某台zkServer获得了超过半数的选票，则此zkServer就可以成为Leader了。举个简单的例子：如果现在集群中有5台zkServer，那么half=5/2=2，那么也就是说，领导者选举的过程中至少要有三台zkServer投了同一个zkServer，才会符合过半机制，才能选出来一个Leader。")]),e._v(" "),r("p",[e._v('zookeeper过半机制中**为什么是大于，而不是大于等于？**这就是和脑裂问题有关系了，比如：当机房中间的网络断掉之后，机房1内的三台服务器会进行领导者选举，但是此时过半机制的条件是 "节点数 > 3"，也就是说至少要4台zkServer才能选出来一个Leader，所以对于机房1来说它不能选出一个Leader，同样机房2也不能选出一个Leader，这种情况下整个集群当机房间的网络断掉后，整个集群将没有Leader。而如果过半机制的条件是 "节点数 >= 3"，那么机房1和机房2都会选出一个Leader，这样就出现了脑裂。')]),e._v(" "),r("p",[r("strong",[e._v("这就可以解释为什么过半机制中是大于而不是大于等于，目的就是为了防止脑裂。")])]),e._v(" "),r("h1",{attrs:{id:"zk实现分布式锁"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#zk实现分布式锁"}},[e._v("#")]),e._v(" zk实现分布式锁")]),e._v(" "),r("p",[e._v("首先用到zookeeper中的两个重要知识点：")]),e._v(" "),r("ul",[r("li",[e._v("zookeeper中的节点类型：临时节点、临时有序节点、持久节点、持久有序节点。临时节点跟session关联。")]),e._v(" "),r("li",[e._v("zookeeper的watch。以上两点就是实现分布式锁的核心点。")])]),e._v(" "),r("p",[e._v("1、创建一个"),r("strong",[e._v("节点lock")]),e._v("作为锁的根节点，当有线程需要抢锁的时候在该节点下创建一个"),r("strong",[e._v("临时有序节点")])]),e._v(" "),r("p",[e._v("2、节点创建成功后，获取当前根节点下的所有孩子节点列表，并将自己阻塞住")]),e._v(" "),r("p",[e._v("3、因为获取到的子节点列表是无序的，所以需要先对子节点进行排序，然后判断自己是不是当前的第一个子节点，如果自己是第一个子节点说明抢到锁可以执行业务代码")]),e._v(" "),r("p",[e._v("4、如果自己不是第一个子节点，获取到自己当前在列表中索引，去监听自己的前一个节点，也就是自己的索引  index -1   （这里的监听前一个节点为核心，如果我们去监听根节点，那么一个节点的删除就需要回调所有的子节点代价太大，所以是监听前一个节点）")]),e._v(" "),r("p",[e._v("5、当获得锁的节点执行释放锁，也就是删除自己的节点时，后边监听的节点收到回调事件后再去获取所有的子节点，再去判断自己是不是第一个，执行抢锁操作")])])}),[],!1,null,null,null);r.default=o.exports}}]);